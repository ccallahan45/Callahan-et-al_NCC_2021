{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacific temperature indices in the LongRunMIP - Nino3/Nino3.4/Nino4\n",
    "#### Christopher Callahan\n",
    "#### Christopher.W.Callahan.GR@dartmouth.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate indices for El Nino temperature anomalies in the LongRunMIP models. Nino3, Nino4, Nino3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mechanics\n",
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "from matplotlib.patches import Polygon\n",
    "from scipy import signal\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model formal names list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnames_fig = ['CCSM3 abrupt 2x','CCSM3 abrupt 4x','CCSM3 abrupt 8x', \\\n",
    "    'CESM1.0.4 abrupt 2x','CESM1.0.4 abrupt 4x','CESM1.0.4 abrupt 8x', 'CNRM-CM6.1 abrupt4x', \\\n",
    "    'GFDL-CM3 1pct 2x','GFDL-ESM2M 1pct 2x','GISS-E2-R 1pct 4x', \\\n",
    "    'GISS-E2-R abrupt 4x','HadCM3L abrupt 2x','HadCM3L abrupt 4x', \\\n",
    "    'HadCM3L abrupt 6x','HadCM3L abrupt 8x','IPSL-CM5A-LR abrupt 4x', \\\n",
    "    'MIROC3.2 1pct 2x','MIROC3.2 1pct 4x','MPIESM-1.2 abrupt 2x', \\\n",
    "    'MPIESM-1.2 abrupt 4x','MPIESM-1.2 abrupt 8x']\n",
    "\n",
    "modelnames_file = ['CCSM3_abrupt2x','CCSM3_abrupt4x','CCSM3_abrupt8x', \\\n",
    "    'CESM104_abrupt2x','CESM104_abrupt4x','CESM104_abrupt8x', \\\n",
    "    'CNRMCM61_abrupt4x','GFDLCM3_1pct2x','GFDLESM2M_1pct2x','GISSE2R_1pct4x', \\\n",
    "    'GISSE2R_abrupt4x','HadCM3L_abrupt2x','HadCM3L_abrupt4x', \\\n",
    "    'HadCM3L_abrupt6x','HadCM3L_abrupt8x','IPSLCM5A_abrupt4x', \\\n",
    "    'MIROC32_1pct2x','MIROC32_1pct4x','MPIESM12_abrupt2x', \\\n",
    "    'MPIESM12_abrupt4x','MPIESM12_abrupt8x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tas = \"~/\" # change if using raw data\n",
    "loc_out = \"../Data/ENSO_Indices/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom detrending function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_detrend(data,order):\n",
    "    \n",
    "    # only for one-dimensional timeseries\n",
    "    # numpy required\n",
    "    \n",
    "    x = np.arange(1,len(data)+1,1)\n",
    "    \n",
    "    model = np.polyfit(x,data,order)\n",
    "    predicted = np.polyval(model,x)\n",
    "    new = data - predicted\n",
    "    \n",
    "    return(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for listing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(directory, extension):\n",
    "    \n",
    "    # Credit to: http://www.martinbroadhurst.com/listing-all-files-in-a-directory-with-a-certain-extension-in-python.html\n",
    "    # Requires os.listdir\n",
    "    \n",
    "    return (f for f in os.listdir(directory) if f.endswith(extension))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [\"nino3\",\"nino34\",\"nino4\"]\n",
    "\n",
    "lat_mins = [-5,-5,-5]\n",
    "lat_maxs = [5,5,5]\n",
    "lon_mins = [210,190,160]\n",
    "lon_maxs = [270,240,210]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detrending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordr = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "Loop through experiments, calculate area-average, output as \"raw\" timeseries, then calculate anomalies and detrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPIESM12_abrupt8x\n",
      "loading data for nino3...\n",
      "writing out raw indices...\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino3_MPIESM12_abrupt8x_raw.nc\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino3_MPIESM12_control_raw.nc\n",
      "detrending and calculating anomalies...\n",
      "writing out dt/anom indices...\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino3_MPIESM12_abrupt8x_anom_detrend2.nc\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino3_MPIESM12_control_anom_detrend2.nc\n",
      "loading data for nino34...\n",
      "writing out raw indices...\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino34_MPIESM12_abrupt8x_raw.nc\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino34_MPIESM12_control_raw.nc\n",
      "detrending and calculating anomalies...\n",
      "writing out dt/anom indices...\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino34_MPIESM12_abrupt8x_anom_detrend2.nc\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino34_MPIESM12_control_anom_detrend2.nc\n",
      "loading data for nino4...\n",
      "writing out raw indices...\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino4_MPIESM12_abrupt8x_raw.nc\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino4_MPIESM12_control_raw.nc\n",
      "detrending and calculating anomalies...\n",
      "writing out dt/anom indices...\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino4_MPIESM12_abrupt8x_anom_detrend2.nc\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino4_MPIESM12_control_anom_detrend2.nc\n",
      "MPIESM11_abrupt4x\n",
      "loading data for nino3...\n",
      "writing out raw indices...\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino3_MPIESM11_abrupt4x_raw.nc\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino3_MPIESM11_control_raw.nc\n",
      "detrending and calculating anomalies...\n",
      "writing out dt/anom indices...\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino3_MPIESM11_abrupt4x_anom_detrend2.nc\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino3_MPIESM11_control_anom_detrend2.nc\n",
      "loading data for nino34...\n",
      "writing out raw indices...\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino34_MPIESM11_abrupt4x_raw.nc\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino34_MPIESM11_control_raw.nc\n",
      "detrending and calculating anomalies...\n",
      "writing out dt/anom indices...\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino34_MPIESM11_abrupt4x_anom_detrend2.nc\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino34_MPIESM11_control_anom_detrend2.nc\n",
      "loading data for nino4...\n",
      "writing out raw indices...\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino4_MPIESM11_abrupt4x_raw.nc\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino4_MPIESM11_control_raw.nc\n",
      "detrending and calculating anomalies...\n",
      "writing out dt/anom indices...\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino4_MPIESM11_abrupt4x_anom_detrend2.nc\n",
      "/dartfs-hpc/rc/lab/C/CMIG/ccallahan/ENSO/NINO_INDICES/nino4_MPIESM11_control_anom_detrend2.nc\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0,len(modelnames_file),1):\n",
    "    \n",
    "    model, exp = modelnames_file[i].split(\"_\")\n",
    "    print(modelnames_file[i])\n",
    "    \n",
    "    fname_exp_start = \"tas_mon_\"+modelnames_file[i]\n",
    "    fname_control_start = \"tas_mon_\"+model+\"_control\"\n",
    "    \n",
    "    fname_exp = [f for f in os.listdir(loc_tas) if f.startswith(fname_exp_start)][0]\n",
    "    fname_control = [f for f in os.listdir(loc_tas) if f.startswith(fname_control_start)][0]\n",
    "    \n",
    "    n1, n2, n3, n4, year_exp_nc = fname_exp.split(\"_\")\n",
    "    n1, n2, n3, n4, year_control_nc = fname_control.split(\"_\")\n",
    "    year_exp, nc = year_exp_nc.split(\".\")\n",
    "    year_control, nc = year_control_nc.split(\".\")\n",
    "    \n",
    "    # In this script we're repeatedly doing the calculations for the control, for each experiment\n",
    "    # That is, this loop for CESM abrupt2x and abrupt4x does the exact same calculation on the\n",
    "    # CESM control and re-writes the file\n",
    "    # but I'm too lazy to be more precise about it\n",
    "    \n",
    "    model_decode_times_list = [\"MIROC32\",\"MPIESM12\"]\n",
    "    \n",
    "    for j in np.arange(0,len(indices),1):\n",
    "        print(\"loading data for \"+indices[j]+\"...\")\n",
    "        \n",
    "        if model in model_decode_times_list:\n",
    "            tas_exp_global = xr.DataArray(xr.open_dataset(loc_tas+fname_exp,decode_times=False).data_vars[\"tas\"])\n",
    "            tas_control_global = xr.DataArray(xr.open_dataset(loc_tas+fname_control,decode_times=False).data_vars[\"tas\"])\n",
    "        else:\n",
    "            tas_exp_global = xr.DataArray(xr.open_dataset(loc_tas+fname_exp).data_vars[\"tas\"])\n",
    "            tas_control_global = xr.DataArray(xr.open_dataset(loc_tas+fname_control).data_vars[\"tas\"])\n",
    "            \n",
    "        if model == \"HadCM3L\":\n",
    "            lat_tas = tas_exp_global.coords[\"latitude_1\"]\n",
    "            lon_tas = tas_exp_global.coords[\"longitude_1\"]\n",
    "        else:\n",
    "            lat_tas = tas_exp_global.coords[\"lat\"]\n",
    "            lon_tas = tas_exp_global.coords[\"lon\"]\n",
    "            \n",
    "        if lat_tas[0] > lat_tas[len(lat_tas.values)-1]:\n",
    "            index_exp_raw = tas_exp_global.loc[:,lat_maxs[j]:lat_mins[j],lon_mins[j]:lon_maxs[j]].mean(axis=(1,2))\n",
    "            index_control_raw = tas_control_global.loc[:,lat_maxs[j]:lat_mins[j],lon_mins[j]:lon_maxs[j]].mean(axis=(1,2))\n",
    "        else:\n",
    "            index_exp_raw = tas_exp_global.loc[:,lat_mins[j]:lat_maxs[j],lon_mins[j]:lon_maxs[j]].mean(axis=(1,2))\n",
    "            index_control_raw = tas_control_global.loc[:,lat_mins[j]:lat_maxs[j],lon_mins[j]:lon_maxs[j]].mean(axis=(1,2))\n",
    "        \n",
    "        #index_exp_raw = tas_exp.mean(dim=[\"lat\",\"lon\"])\n",
    "        #index_control_raw = tas_exp.mean(dim=[\"lat\",\"lon\"])\n",
    "        \n",
    "        # attach time arrays to allow us to calculate anomalies\n",
    "        if model == \"MPIESM11\":\n",
    "            n_years_c = index_control_raw.shape[0]\n",
    "            n_years_f = index_exp_raw.shape[0]\n",
    "            time_exp = xr.cftime_range(start='0001', periods=n_years_f, freq='YS')\n",
    "            time_control = xr.cftime_range(start='0001', periods=n_years_c, freq='YS')\n",
    "        else:\n",
    "            n_months_c = index_control_raw.shape[0]\n",
    "            n_months_f = index_exp_raw.shape[0]\n",
    "            time_exp = xr.cftime_range(start='0001', periods=n_months_f, freq='M')\n",
    "            time_control = xr.cftime_range(start='0001', periods=n_months_c, freq='M')\n",
    "            \n",
    "        index_exp_time = xr.DataArray(index_exp_raw.values,coords=[time_exp],dims=[\"time\"])\n",
    "        index_control_time = xr.DataArray(index_control_raw.values,coords=[time_control],dims=[\"time\"])\n",
    "        \n",
    "        print(\"writing out raw indices...\")\n",
    "        # write out raw index from experiment\n",
    "        index_exp_time.name = indices[j]\n",
    "        index_exp_time.attrs[\"creation_date\"] = str(datetime.datetime.now())\n",
    "        index_exp_time.attrs[\"created_by\"] = \"Christopher Callahan, Christopher.W.Callahan.GR@dartmouth.edu\"\n",
    "        index_exp_time.attrs[\"data_description\"] = indices[j]+\" from \"+model+\" \"+exp+\", raw (not anomaly)\"\n",
    "        index_exp_time.attrs[\"created_from\"] = \"Calculate_Nino_Indices.ipynb\"\n",
    "        \n",
    "        fname_out_exp_raw = loc_out+indices[j]+\"_\"+\"_\"+model+\"_\"+exp+\"_raw.nc\"\n",
    "        index_exp_time.to_netcdf(fname_out_exp_raw,mode=\"w\")\n",
    "        print(fname_out_exp_raw)\n",
    "        \n",
    "        \n",
    "        # write out raw index from control\n",
    "        index_control_time.name = indices[j]\n",
    "        index_control_time.attrs[\"creation_date\"] = str(datetime.datetime.now())\n",
    "        index_control_time.attrs[\"created_by\"] = \"Christopher Callahan, Christopher.W.Callahan.GR@dartmouth.edu\"\n",
    "        index_control_time.attrs[\"data_description\"] = indices[j]+\" from \"+model+\" control, raw (not anomaly)\"\n",
    "        index_control_time.attrs[\"created_from\"] = \"Calculate_Nino_Indices.ipynb\"\n",
    "        \n",
    "        fname_out_control_raw = loc_out+indices[j]+\"_\"+model+\"_control_raw.nc\"\n",
    "        index_control_time.to_netcdf(fname_out_control_raw,mode=\"w\")\n",
    "        print(fname_out_control_raw)\n",
    "        \n",
    "        print(\"detrending and calculating anomalies...\")\n",
    "        # detrend fast/transient/eq (if abrupt) and transient/eq (if 1pct)\n",
    "        # then calculate anomalies\n",
    "        \n",
    "        # detrend control\n",
    "        index_ctrl_detrend = xr.DataArray(custom_detrend(index_control_time,ordr).values,coords=[index_control_time.coords[\"time\"]],dims=[\"time\"])\n",
    "        if model == \"MPIESM11\":\n",
    "            index_ctrl_anom = index_ctrl_detrend - np.mean(index_ctrl_detrend.values)\n",
    "            #index_ctrl_anom = index_ctrl_detrend.groupby(\"time.year\") - (index_ctrl_detrend.groupby(\"time.year\").mean(dim=\"time\"))\n",
    "        else:\n",
    "            index_ctrl_anom = index_ctrl_detrend.groupby(\"time.month\") - (index_ctrl_detrend.groupby(\"time.month\").mean(dim=\"time\"))\n",
    "        \n",
    "        \n",
    "        # conditional for abrupt/1pct\n",
    "        if model == \"MPIESM11\": # monthly vs annual data\n",
    "            ntimes_peryear = 1\n",
    "        else:\n",
    "            ntimes_peryear = 12\n",
    "        \n",
    "        if exp.startswith(\"abrupt\"):\n",
    "            \n",
    "            index_fast = index_exp_time[0:(50*ntimes_peryear)]\n",
    "            index_transient = index_exp_time[(50*ntimes_peryear):(150*ntimes_peryear)]\n",
    "            index_eq = index_exp_time[(150*ntimes_peryear):]\n",
    "            \n",
    "            index_fast_detrend = xr.DataArray(custom_detrend(index_fast,ordr).values,coords=[index_fast.coords[\"time\"]],dims=[\"time\"])\n",
    "            index_transient_detrend = xr.DataArray(custom_detrend(index_transient,ordr).values,coords=[index_transient.coords[\"time\"]],dims=[\"time\"])\n",
    "            index_eq_detrend = xr.DataArray(custom_detrend(index_eq,ordr).values,coords=[index_eq.coords[\"time\"]],dims=[\"time\"])\n",
    "            \n",
    "            if model == \"MPIESM11\":\n",
    "                index_fast_anom = index_fast_detrend - np.mean(index_fast_detrend.values)\n",
    "                index_transient_anom = index_transient_detrend - np.mean(index_transient_detrend.values)\n",
    "                index_eq_anom = index_eq_detrend - np.mean(index_eq_detrend.values)\n",
    "            else:\n",
    "                index_fast_anom = index_fast_detrend.groupby(\"time.month\") - (index_fast_detrend.groupby(\"time.month\").mean(dim=\"time\"))\n",
    "                index_transient_anom = index_transient_detrend.groupby(\"time.month\") - (index_transient_detrend.groupby(\"time.month\").mean(dim=\"time\"))\n",
    "                index_eq_anom = index_eq_detrend.groupby(\"time.month\") - (index_eq_detrend.groupby(\"time.month\").mean(dim=\"time\"))\n",
    "\n",
    "            index_exp_anom = xr.concat([index_fast_anom,index_transient_anom,index_eq_anom],dim=\"time\")\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            index_transient = index_exp_time[0:(140*ntimes_peryear)]\n",
    "            index_eq = index_exp_time[(140*ntimes_peryear):]\n",
    "            \n",
    "            index_transient_detrend = xr.DataArray(custom_detrend(index_transient,ordr).values,coords=[index_transient.coords[\"time\"]],dims=[\"time\"])\n",
    "            index_eq_detrend = xr.DataArray(custom_detrend(index_eq,ordr).values,coords=[index_eq.coords[\"time\"]],dims=[\"time\"])\n",
    "            \n",
    "            if model == \"MPIESM11\":\n",
    "                index_transient_anom = index_transient_detrend - np.mean(index_transient_detrend.values)\n",
    "                index_eq_anom = index_eq_detrend - np.mean(index_eq_detrend.values)\n",
    "            else:\n",
    "                index_transient_anom = index_transient_detrend.groupby(\"time.month\") - (index_transient_detrend.groupby(\"time.month\").mean(dim=\"time\"))\n",
    "                index_eq_anom = index_eq_detrend.groupby(\"time.month\") - (index_eq_detrend.groupby(\"time.month\").mean(dim=\"time\"))\n",
    "\n",
    "            index_exp_anom = xr.concat([index_transient_anom,index_eq_anom],dim=\"time\")\n",
    "            \n",
    "        \n",
    "        print(\"writing out dt/anom indices...\")\n",
    "        # write out index from experiment\n",
    "        index_exp_anom.name = indices[j]\n",
    "        index_exp_anom.attrs[\"creation_date\"] = str(datetime.datetime.now())\n",
    "        index_exp_anom.attrs[\"created_by\"] = \"Christopher Callahan, Christopher.W.Callahan.GR@dartmouth.edu\"\n",
    "        index_exp_anom.attrs[\"data_description\"] = indices[j]+\" from \"+model+\" \"+exp+\", anomaly and detrended using order in file name\"\n",
    "        index_exp_anom.attrs[\"created_from\"] = \"Calculate_Nino_Indices.ipynb\"\n",
    "        \n",
    "        fname_out_exp_anom = loc_out+indices[j]+\"_\"+model+\"_\"+exp+\"_anom_detrend\"+str(ordr)+\".nc\"\n",
    "        index_exp_anom.to_netcdf(fname_out_exp_anom,mode=\"w\")\n",
    "        print(fname_out_exp_anom)\n",
    "        \n",
    "        \n",
    "        # write out index from control\n",
    "        index_ctrl_anom.name = indices[j]\n",
    "        index_ctrl_anom.attrs[\"creation_date\"] = str(datetime.datetime.now())\n",
    "        index_ctrl_anom.attrs[\"created_by\"] = \"Christopher Callahan, Christopher.W.Callahan.GR@dartmouth.edu\"\n",
    "        index_ctrl_anom.attrs[\"data_description\"] = indices[j]+\" from \"+model+\" control, anomaly and detrended using order in file name\"\n",
    "        index_ctrl_anom.attrs[\"created_from\"] = \"Calculate_Nino_Indices.ipynb\"\n",
    "        \n",
    "        fname_out_control_anom = loc_out+indices[j]+\"_\"+model+\"_control_anom_detrend\"+str(ordr)+\".nc\"\n",
    "        index_ctrl_anom.to_netcdf(fname_out_control_anom,mode=\"w\")\n",
    "        print(fname_out_control_anom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ccallahan",
   "language": "python",
   "name": "ccallahan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
