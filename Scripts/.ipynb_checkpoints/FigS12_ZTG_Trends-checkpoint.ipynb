{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unforced trends in ZTG and ENSO in control simulations\n",
    "#### Christopher Callahan\n",
    "#### Christopher.W.Callahan.GR@dartmouth.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mechanics\n",
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "from matplotlib.patches import Polygon\n",
    "from scipy import signal\n",
    "from eofs.xarray import Eof\n",
    "from scipy import stats\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import numpy.polynomial.polynomial as poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models - only one simulation per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnames_fig = ['CCSM3 abrupt 4x', \\\n",
    "    'CESM1.0.4 abrupt 4x','CNRM-CM6.1 abrupt 4x', \\\n",
    "    'GFDL-CM3 1pct 2x','GFDL-ESM2M 1pct 2x', \\\n",
    "    'GISS-E2-R abrupt 4x','HadCM3L abrupt 4x', \\\n",
    "    'IPSL-CM5A-LR abrupt 4x', \\\n",
    "    'MIROC3.2 1pct 4x', \\\n",
    "    'MPIESM-1.2 abrupt 4x']\n",
    "\n",
    "modelnames_control = ['CCSM3', \\\n",
    "    'CESM1.0.4','CNRM-CM6.1', \\\n",
    "    'GFDL-CM3','GFDL-ESM2M', \\\n",
    "    'GISS-E2-R','HadCM3L', \\\n",
    "    'IPSL-CM5A-LR', \\\n",
    "    'MIROC3.2', \\\n",
    "    'MPIESM-1.2']\n",
    "\n",
    "modelnames_file = ['CCSM3_abrupt4x', \\\n",
    "    'CESM104_abrupt4x','CNRMCM61_abrupt4x', \\\n",
    "    'GFDLCM3_1pct2x','GFDLESM2M_1pct2x', \\\n",
    "    'GISSE2R_abrupt4x','HadCM3L_abrupt4x', \\\n",
    "    'IPSLCM5A_abrupt4x', \\\n",
    "    'MIROC32_1pct4x', \\\n",
    "    'MPIESM12_abrupt4x']\n",
    "\n",
    "\n",
    "colors = [[0,238,0],[34,139,34],[135,206,255],[16,78,139],[30,144,255], \\\n",
    "          [255,110,180],[255,0,0], \\\n",
    "          [255,193,37],[122,55,139],[153,153,153]];\n",
    "\n",
    "colors_double = []\n",
    "for i in np.arange(0,len(colors),1):\n",
    "    colors_double.append(colors[i])\n",
    "    colors_double.append(colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_nino34 = \"../Data/ENSO_Indices/\"\n",
    "loc_ztg = \"../Data/ZTG/\"\n",
    "loc_out = \"../Data/ZTG_Trends/\"\n",
    "loc_hadisst = \"~/\" # change if running with raw data\n",
    "loc_ersst = \"~/\" # change if running with raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear trend function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_trend(ts):\n",
    "    \n",
    "    # This function finds the coefficient on the trend\n",
    "    # on a timeseries (i.e. the regression of the timeseries on time)\n",
    "    # it requires the numpy.polynomial.polynomial package\n",
    "    \n",
    "    # Create time variable\n",
    "    X = np.arange(1,len(ts)+1,1)\n",
    "    \n",
    "    # Fit\n",
    "    Z = poly.polyfit(X,ts,1)\n",
    "    \n",
    "    # Trend coefficient\n",
    "    coef = Z[1]\n",
    "    \n",
    "    return(coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_lengths = [25,35,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_obs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_obs:\n",
    "    hadisst = xr.open_dataset(loc_hadisst+\"HadISST_sst.nc\")\n",
    "    sst = xr.DataArray(hadisst.data_vars[\"sst\"])\n",
    "    lat_sst = sst.coords[\"latitude\"]\n",
    "    lon_sst = sst.coords[\"longitude\"]\n",
    "\n",
    "    lat_min = -5\n",
    "    lat_max = 5\n",
    "    lon_min_nino3 = 210\n",
    "    lon_max_nino3 = 270\n",
    "    lon_min_nino4 = 160\n",
    "    lon_max_nino4 = 210\n",
    "\n",
    "    lon_min_nino3_180 = -150\n",
    "    lon_max_nino3_180 = -90\n",
    "    lon_min_nino4_180 = 160\n",
    "    lon_max_nino4_180 = -150\n",
    "\n",
    "    y1_ersst = 1958\n",
    "    y2_ersst = 2017\n",
    "    for yy in np.arange(y1_ersst,y2_ersst+1,1):\n",
    "        if np.mod(yy,10) == 0:\n",
    "            print(yy)\n",
    "        for mm in np.arange(1,12+1,1):\n",
    "            if mm < 10:\n",
    "                strmm = \"0\"+str(mm)\n",
    "            else:\n",
    "                strmm = str(mm)\n",
    "            ersst_file = xr.open_dataset(loc_ersst+\"ersst.v5.\"+str(yy)+strmm+\".nc\")\n",
    "            sst_ersst_in = xr.DataArray(ersst_file.data_vars[\"sst\"])\n",
    "            if ((yy == y1_ersst) & (mm == 1)):\n",
    "                sst_ersst = sst_ersst_in.loc[:,:,lat_min:lat_max,lon_min_nino4:lon_max_nino3].squeeze(\"lev\")\n",
    "            else:\n",
    "                sst_ersst = xr.concat([sst_ersst,sst_ersst_in.loc[:,:,lat_min:lat_max,lon_min_nino4:lon_max_nino3].squeeze(\"lev\")],dim=\"time\")\n",
    "\n",
    "    nino3_hadisst = sst.loc[:,lat_max:lat_min,lon_min_nino3_180:lon_max_nino3_180].mean(axis=(1,2))\n",
    "    nino4_hadisst = sst[:,:,((lon_sst <= lon_max_nino4_180) | (lon_sst >= lon_min_nino4_180))].loc[:,lat_max:lat_min,:].mean(axis=(1,2))\n",
    "    ztg_hadisst = nino4_hadisst - nino3_hadisst\n",
    "    time_sst = sst.coords[\"time\"]\n",
    "\n",
    "    nino3_ersst = sst_ersst.loc[:,lat_min:lat_max,lon_min_nino3:lon_max_nino3].mean(axis=(1,2))\n",
    "    nino4_ersst = sst_ersst.loc[:,lat_min:lat_max,lon_min_nino4:lon_max_nino4].mean(axis=(1,2))\n",
    "    ztg_ersst = nino4_ersst - nino3_ersst\n",
    "\n",
    "    ztg_obs = ztg_hadisst.loc[\"1958-01-16\":\"2017-12-16\"]\n",
    "    time_obs = np.arange(0,len(ztg_obs),1)\n",
    "    ztg_obs_hadisst = pd.DataFrame(np.transpose([ztg_obs,time_obs]),columns=[\"ZTG\",\"Time\"])\n",
    "    ztg_obs_ersst = pd.DataFrame(np.transpose([ztg_ersst,time_obs]),columns=[\"ZTG\",\"Time\"])\n",
    "    for tt in np.arange(0,len(trend_lengths),1):\n",
    "        trend_model_hadisst = RollingOLS.from_formula(\"ZTG ~ Time\",data=ztg_obs_hadisst,window=trend_lengths[tt]*12)\n",
    "        trend_model_ersst = RollingOLS.from_formula(\"ZTG ~ Time\",data=ztg_obs_ersst,window=trend_lengths[tt]*12)\n",
    "\n",
    "        trend_fit_hadisst = trend_model_hadisst.fit()\n",
    "        trend_fit_ersst = trend_model_ersst.fit()\n",
    "\n",
    "        coefs_hadisst = trend_fit_hadisst.params[\"Time\"].values\n",
    "        coefs_ersst = trend_fit_ersst.params[\"Time\"].values\n",
    "\n",
    "        if tt == 0:\n",
    "            trends_hadisst_1 = coefs_hadisst[~np.isnan(coefs_hadisst)]\n",
    "            trends_ersst_1 = coefs_ersst[~np.isnan(coefs_ersst)]\n",
    "            np.savetxt(loc_out+\"HadISST_trends_\"+str(trend_lengths[tt])+\"yr.csv\",trends_hadisst_1,delimiter=\",\")\n",
    "            np.savetxt(loc_out+\"ERSST_trends_\"+str(trend_lengths[tt])+\"yr.csv\",trends_ersst_1,delimiter=\",\")\n",
    "        elif tt == 1:\n",
    "            trends_hadisst_2 = coefs_hadisst[~np.isnan(coefs_hadisst)]\n",
    "            trends_ersst_2 = coefs_ersst[~np.isnan(coefs_ersst)]\n",
    "            np.savetxt(loc_out+\"HadISST_trends_\"+str(trend_lengths[tt])+\"yr.csv\",trends_hadisst_2,delimiter=\",\")\n",
    "            np.savetxt(loc_out+\"ERSST_trends_\"+str(trend_lengths[tt])+\"yr.csv\",trends_ersst_2,delimiter=\",\")\n",
    "        else:\n",
    "            trends_hadisst_3 = coefs_hadisst[~np.isnan(coefs_hadisst)]\n",
    "            trends_ersst_3 = coefs_ersst[~np.isnan(coefs_ersst)]\n",
    "            np.savetxt(loc_out+\"HadISST_trends_\"+str(trend_lengths[tt])+\"yr.csv\",trends_hadisst_3,delimiter=\",\")\n",
    "            np.savetxt(loc_out+\"ERSST_trends_\"+str(trend_lengths[tt])+\"yr.csv\",trends_ersst_3,delimiter=\",\")\n",
    "else:\n",
    "    trends_hadisst_1 = np.array([x[0] for x in pd.read_csv(loc_out+\"HadISST_trends_\"+str(trend_lengths[0])+\"yr.csv\").values])\n",
    "    trends_ersst_1 = np.array([x[0] for x in pd.read_csv(loc_out+\"ERSST_trends_\"+str(trend_lengths[0])+\"yr.csv\").values])\n",
    "    trends_hadisst_2 = np.array([x[0] for x in pd.read_csv(loc_out+\"HadISST_trends_\"+str(trend_lengths[1])+\"yr.csv\").values])\n",
    "    trends_ersst_2 = np.array([x[0] for x in pd.read_csv(loc_out+\"ERSST_trends_\"+str(trend_lengths[1])+\"yr.csv\").values])\n",
    "    trends_hadisst_3 = np.array([x[0] for x in pd.read_csv(loc_out+\"HadISST_trends_\"+str(trend_lengths[2])+\"yr.csv\").values])\n",
    "    trends_ersst_3 = np.array([x[0] for x in pd.read_csv(loc_out+\"ERSST_trends_\"+str(trend_lengths[2])+\"yr.csv\").values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot distribution of 25, 35, 50-year trends in LongRunMIP control runs along with obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ztg_trends_1 = []\n",
    "ztg_trends_2 = []\n",
    "ztg_trends_3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCSM3_abrupt4x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/site-packages/xarray/coding/times.py:427: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/site-packages/numpy/core/_asarray.py:83: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CESM104_abrupt4x\n",
      "CNRMCM61_abrupt4x\n",
      "GFDLCM3_1pct2x\n",
      "GFDLESM2M_1pct2x\n",
      "GISSE2R_abrupt4x\n",
      "HadCM3L_abrupt4x\n",
      "IPSLCM5A_abrupt4x\n",
      "MIROC32_1pct4x\n",
      "MPIESM12_abrupt4x\n",
      "CCSM3_abrupt4x\n",
      "CESM104_abrupt4x\n",
      "CNRMCM61_abrupt4x\n",
      "GFDLCM3_1pct2x\n",
      "GFDLESM2M_1pct2x\n",
      "GISSE2R_abrupt4x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-be99510ea205>\", line 23, in <module>\n",
      "    trend_fit = trend_model.fit()\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/site-packages/statsmodels/regression/rolling.py\", line 311, in fit\n",
      "    xpy += add_x.T @ wy[i - 1:i]\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "for tt in np.arange(0,len(trend_lengths),1):\n",
    "    print(str(trend_lengths[tt])+\"-yr trends\")\n",
    "    \n",
    "    for i in np.arange(0,len(modelnames_file),1):\n",
    "\n",
    "        model, exp = modelnames_file[i].split(\"_\")\n",
    "        print(modelnames_file[i])\n",
    "\n",
    "        #nino34_control = xr.DataArray(xr.open_dataset(loc_nino34+\"nino34_\"+model+\"_control_anom_detrend.nc\").data_vars[\"nino34\"])\n",
    "\n",
    "        if ((model == \"MIROC32\") | (model == \"MPIESM12\")):\n",
    "            ztg_control = xr.DataArray(xr.open_dataset(loc_ztg+\"ztg_\"+model+\"_control.nc\",decode_times=False).data_vars[\"ztg\"])\n",
    "        else:\n",
    "            ztg_control = xr.DataArray(xr.open_dataset(loc_ztg+\"ztg_\"+model+\"_control.nc\").data_vars[\"ztg\"])\n",
    "\n",
    "        n_months_ztg = ztg_control.shape[0]\n",
    "        time_ztg = np.arange(0,n_months_ztg,1)\n",
    "\n",
    "        #ztg_time_enso = pd.DataFrame(np.transpose([ztg_control,nino34_control,time_ztg]),columns=[\"ZTG\",\"Nino3.4\",\"Time\"])\n",
    "        ztg_time = pd.DataFrame(np.transpose([ztg_control,time_ztg]),columns=[\"ZTG\",\"Time\"])\n",
    "        \n",
    "        # rolling ztg trends\n",
    "        trend_model = RollingOLS.from_formula(\"ZTG ~ Time\",data=ztg_time,window=trend_lengths[tt]*12)\n",
    "        trend_fit = trend_model.fit()\n",
    "        coefs = trend_fit.params[\"Time\"].values\n",
    "        coefs_nan = coefs[~np.isnan(coefs)]\n",
    "        \n",
    "        if tt == 0:\n",
    "            ztg_trends_1.append(coefs_nan)\n",
    "        elif tt == 1:\n",
    "            ztg_trends_2.append(coefs_nan)\n",
    "        elif tt == 2:\n",
    "            ztg_trends_3.append(coefs_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_all = ['HadISST','ERSST','CCSM3', \\\n",
    "    'CESM1.0.4','CNRM-CM6.1', \\\n",
    "    'GFDL-CM3','GFDL-ESM2M', \\\n",
    "    'GISS-E2-R','HadCM3L', \\\n",
    "    'IPSL-CM5A-LR', \\\n",
    "    'MIROC3.2', \\\n",
    "    'MPIESM-1.2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_boxplot_col(b,n,c,c_double,lw,median):\n",
    "    \n",
    "    # This function sets the colors of a given boxplot b\n",
    "    # It auto-sets the colors of the boxes, whiskers, caps, and fliers to c[m]\n",
    "    # and it sets the colors of the medians if median=True\n",
    "    # n is the number of instances of the boxplot and lw is the desired\n",
    "    # linewidth\n",
    "    # c should be a vector of colors\n",
    "    \n",
    "    for m in range(0,n*2,1):\n",
    "        if m < n:\n",
    "            b[\"boxes\"][m].set(color=c[m],linewidth=lw)\n",
    "            b[\"whiskers\"][m].set(color=c_double[m],linewidth=lw)\n",
    "            b[\"caps\"][m].set(color=c_double[m],linewidth=lw)\n",
    "            b[\"fliers\"][m].set(markeredgecolor=c[m])\n",
    "            if median==True:\n",
    "                b[\"medians\"][m].set(color=c[m],linewidth=lw)\n",
    "        else:\n",
    "            b[\"whiskers\"][m].set(color=c_double[m],linewidth=lw)\n",
    "            b[\"caps\"][m].set(color=c_double[m],linewidth=lw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "\n",
    "rcParams[\"font.family\"] = \"sans-serif\"\n",
    "rcParams[\"font.sans-serif\"] = [\"Helvetica Neue\"]\n",
    "rcParams[\"font.size\"] = 22.0\n",
    "rcParams[\"axes.linewidth\"] = 1.5\n",
    "rcParams['xtick.major.size'] = 8\n",
    "rcParams['xtick.major.width'] = 1.5\n",
    "rcParams['ytick.major.size'] = 8\n",
    "rcParams['ytick.major.width'] = 1.5\n",
    "\n",
    "\n",
    "col = [0.8,0.2,0.2]\n",
    "#col = \"darkorange\"\n",
    "\n",
    "#cols = [\"orange\",\"green\",\"blue\",\"red\",\"black\",\"gray\",\"purple\"]\n",
    "\n",
    "cols = [[0,238,0],\\\n",
    "          [34,139,34],[135,206,255],[16,78,139],[30,144,255], \\\n",
    "          [255,110,180],[255,0,0],\\\n",
    "          [255,193,37],[122,55,139],[153,153,153]];\n",
    "\n",
    "\n",
    "gs5 = gridspec.GridSpec(1,2)\n",
    "gs5.update(left=0.1,right=0.95,top=0.9,bottom=0.21,wspace=0.2,hspace=0.25)\n",
    "\n",
    "pvals_hadisst = np.zeros((3,10))\n",
    "pvals_ersst = np.zeros((3,10))\n",
    "\n",
    "for tt in np.arange(0,len(trend_lengths)-1,1):\n",
    "    \n",
    "    ax = plt.subplot(gs5[0,tt])\n",
    "\n",
    "    if tt == 0:\n",
    "        ztg_trends = ztg_trends_1*120\n",
    "        hadisst_trends = trends_hadisst_1*120\n",
    "        ersst_trends = trends_ersst_1*120\n",
    "    elif tt == 1:\n",
    "        ztg_trends = ztg_trends_2*120\n",
    "        hadisst_trends = trends_hadisst_2*120\n",
    "        ersst_trends = trends_ersst_2*120\n",
    "    elif tt == 2:\n",
    "        ztg_trends = ztg_trends_3*120\n",
    "        hadisst_trends = trends_hadisst_3*120\n",
    "        ersst_trends = trends_ersst_3*120\n",
    "    \n",
    "    b1 = plt.boxplot(ztg_trends,positions=np.arange(1,11,1),whis=[5,95],\n",
    "                     flierprops=dict(markersize=3),widths=0.6)\n",
    "    set_boxplot_col(b1,10,np.array(colors)/255.,np.array(colors_double)/255.,2,True)\n",
    "    \n",
    "    b2 = plt.boxplot([hadisst_trends,ersst_trends],positions=[-1,0],whis=[5,95],\n",
    "                     flierprops=dict(markersize=3),widths=0.6)\n",
    "    black_cols = np.array([\"black\",\"black\"])\n",
    "    black_cols_double = np.array([\"black\",\"black\",\"black\",\"black\"])\n",
    "    set_boxplot_col(b2,2,black_cols,black_cols_double,2,True)\n",
    "    \n",
    "    plt.title(str(trend_lengths[tt])+\"-Year Trends\",pad=10)\n",
    "    \n",
    "    if tt == 0:\n",
    "        plt.ylabel(\"ZTG Trend ($\\degree$C per decade)\")\n",
    "    plt.ylim([-0.63,0.63])\n",
    "    plt.xlim([-2,11])\n",
    "    \n",
    "    plt.xticks(ticks=np.arange(-1,11,1),labels=names_all,rotation=40,ha=\"right\",\n",
    "              rotation_mode=\"anchor\")\n",
    "    plt.axhline(y=0,linewidth=1.5,linestyle=\"-\",color=\"black\")\n",
    "    \n",
    "\n",
    "plt.figtext(0.09,0.95,\"a\",fontsize=40)\n",
    "plt.figtext(0.55,0.95,\"b\",fontsize=40)\n",
    "\n",
    "plt.savefig(\"../Figures/FigS12_ZTG_Trends.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ccallahan",
   "language": "python",
   "name": "ccallahan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
